{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e9ecc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import all the nessacary libraries to run the pose estimator\n",
    "\n",
    "#Import mediapipe to be used for the model\n",
    "import mediapipe as mp\n",
    "#Import opencv for rendaring and drawing capabilities\n",
    "import cv2\n",
    "\n",
    "import numpy as np #Handle numpy arrays\n",
    "import pandas as pd #Handle tabular data\n",
    "import os #Handle folder structure\n",
    "import pickle #Save and oad ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4859f1df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Loaded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('randomforestclassifier', RandomForestClassifier())])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import the model from the binary file\n",
    "with open('rf_model.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "    print(\"Model Loaded\")\n",
    "    \n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b47a8aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: Incorrect\n",
      "[0.41 0.59]\n",
      "Class: Incorrect\n",
      "[0.42 0.58]\n",
      "Class: Incorrect\n",
      "[0.42 0.58]\n",
      "Class: Incorrect\n",
      "[0.43 0.57]\n",
      "Class: Incorrect\n",
      "[0.46 0.54]\n",
      "Class: Incorrect\n",
      "[0.42 0.58]\n",
      "Class: Incorrect\n",
      "[0.41 0.59]\n",
      "Class: Incorrect\n",
      "[0.41 0.59]\n",
      "Class: Incorrect\n",
      "[0.42 0.58]\n",
      "Class: Incorrect\n",
      "[0.44 0.56]\n",
      "Class: Incorrect\n",
      "[0.42 0.58]\n",
      "Class: Incorrect\n",
      "[0.44 0.56]\n",
      "Class: Incorrect\n",
      "[0.44 0.56]\n",
      "Class: Incorrect\n",
      "[0.44 0.56]\n",
      "Class: Incorrect\n",
      "[0.44 0.56]\n",
      "Class: Incorrect\n",
      "[0.46 0.54]\n",
      "Class: Correct\n",
      "[0.57 0.43]\n",
      "Class: Correct\n",
      "[0.6 0.4]\n",
      "Class: Correct\n",
      "[0.61 0.39]\n",
      "Class: Correct\n",
      "[0.59 0.41]\n",
      "Class: Correct\n",
      "[0.54 0.46]\n",
      "Class: Correct\n",
      "[0.6 0.4]\n",
      "Class: Correct\n",
      "[0.59 0.41]\n",
      "Class: Correct\n",
      "[0.58 0.42]\n",
      "Class: Correct\n",
      "[0.53 0.47]\n",
      "Class: Correct\n",
      "[0.53 0.47]\n",
      "Class: Correct\n",
      "[0.53 0.47]\n",
      "Class: Correct\n",
      "[0.52 0.48]\n",
      "Class: Correct\n",
      "[0.52 0.48]\n",
      "Class: Correct\n",
      "[0.52 0.48]\n",
      "Class: Correct\n",
      "[0.52 0.48]\n",
      "Class: Correct\n",
      "[0.52 0.48]\n",
      "Class: Correct\n",
      "[0.52 0.48]\n",
      "Class: Correct\n",
      "[0.52 0.48]\n",
      "Class: Correct\n",
      "[0.52 0.48]\n",
      "Class: Correct\n",
      "[0.52 0.48]\n",
      "Class: Correct\n",
      "[0.52 0.48]\n",
      "Class: Correct\n",
      "[0.52 0.48]\n",
      "Class: Correct\n",
      "[0.52 0.48]\n",
      "Class: Correct\n",
      "[0.53 0.47]\n",
      "Class: Correct\n",
      "[0.53 0.47]\n",
      "Class: Correct\n",
      "[0.52 0.48]\n",
      "Class: Correct\n",
      "[0.55 0.45]\n",
      "Class: Correct\n",
      "[0.57 0.43]\n",
      "Class: Correct\n",
      "[0.62 0.38]\n",
      "Class: Correct\n",
      "[0.62 0.38]\n",
      "Class: Correct\n",
      "[0.66 0.34]\n",
      "Class: Correct\n",
      "[0.62 0.38]\n",
      "Class: Correct\n",
      "[0.61 0.39]\n",
      "Class: Correct\n",
      "[0.56 0.44]\n",
      "Class: Correct\n",
      "[0.55 0.45]\n",
      "Class: Correct\n",
      "[0.54 0.46]\n",
      "Class: Incorrect\n",
      "[0.48 0.52]\n",
      "Class: Incorrect\n",
      "[0.48 0.52]\n",
      "Class: Incorrect\n",
      "[0.46 0.54]\n",
      "Class: Incorrect\n",
      "[0.45 0.55]\n",
      "Class: Incorrect\n",
      "[0.45 0.55]\n",
      "Class: Incorrect\n",
      "[0.45 0.55]\n",
      "Class: Incorrect\n",
      "[0.46 0.54]\n",
      "Class: Incorrect\n",
      "[0.46 0.54]\n",
      "Class: Incorrect\n",
      "[0.46 0.54]\n",
      "Class: Incorrect\n",
      "[0.46 0.54]\n",
      "Class: Incorrect\n",
      "[0.45 0.55]\n",
      "Class: Incorrect\n",
      "[0.45 0.55]\n",
      "Class: Incorrect\n",
      "[0.45 0.55]\n",
      "Class: Incorrect\n",
      "[0.44 0.56]\n",
      "Class: Incorrect\n",
      "[0.44 0.56]\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "#Display the results of the prediction done by the model\n",
    "\n",
    "holistic_model = mp.solutions.holistic \n",
    "\n",
    "#Connect the test video from the device\n",
    "sample_video = cv2.VideoCapture('datasets/test/valid/5.valid.mp4')\n",
    "\n",
    "#Load the holistic model\n",
    "with holistic_model.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "    #Loop through each frame of the video \n",
    "    while sample_video.isOpened():\n",
    "        #Returns the status of the read and the frame as an image\n",
    "        status, frame = sample_video.read()\n",
    "        \n",
    "        #If frame is read correctly, status is true\n",
    "        if status == False:\n",
    "            print(\"Done\")\n",
    "            break\n",
    "          \n",
    "        #Recolor the captured frame from BGR to RGB (Medipipe requies frames to be in RGB format)\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        #Prevent writing and copying frame data to improve performance while making the detection\n",
    "        rgb_frame.flags.writeable = False        \n",
    "        \n",
    "        #Use holistic model to make detections\n",
    "        result_frame = holistic.process(rgb_frame)\n",
    "        \n",
    "        #Set frame back to writable format after detection\n",
    "        rgb_frame.flags.writeable = True   \n",
    "        \n",
    "        #Recolor the captured frame from BGR for rendering with opencv\n",
    "        bgr_frame = cv2.cvtColor(rgb_frame, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "         #Predict the coordinates of the landmarks (resulrs screen)\n",
    "        try:\n",
    "            #Extracting all the landmarks of the pose as an array\n",
    "            pose_landmarks_array = result_frame.pose_landmarks.landmark\n",
    "            #Format landmarks in to a numpy array for better structuring(removing keys) and collapse array to 1 dimesnsion\n",
    "            pose_landmarks_nparray = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in pose_landmarks_array]).flatten())\n",
    "\n",
    "            #Pass the numpy array into a data frame\n",
    "            features = pd.DataFrame([pose_landmarks_nparray])\n",
    "            \n",
    "            #Store the top class of the prediction\n",
    "            pose_class_status = model.predict(features.values)[0]\n",
    "            #Store the probability of the prediction\n",
    "            pose_class_status_prob = model.predict_proba(features.values)[0]\n",
    "            \n",
    "            print(\"Class:\", pose_class_status)\n",
    "            print(pose_class_status_prob)\n",
    "            \n",
    "            #Set a rectangle box to display the results of the prediction in the video frame\n",
    "            #rectangle(container, top_coord, bottom_coord, color, line_thickness)\n",
    "            cv2.rectangle(bgr_frame, (0,0), (250, 60), (245, 117, 16), -1)\n",
    "            \n",
    "            #Display the class label inside the rectangle box\n",
    "            cv2.putText(bgr_frame, 'Class'\n",
    "                        , (95,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "            \n",
    "            #Extract =and display the top class of the prediction\n",
    "            cv2.putText(bgr_frame, pose_class_status.split(' ')[0]\n",
    "                        , (90,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            #Display the class probability inside the rectangle box\n",
    "            cv2.putText(bgr_frame, 'Probability'\n",
    "                        , (15,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "            \n",
    "            #Extract and dispthe maximum probability\n",
    "            cv2.putText(bgr_frame, str(round(pose_class_status_prob[np.argmax(pose_class_status_prob)],2))\n",
    "                        , (10,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    " \n",
    "        except:\n",
    "            pass\n",
    "                        \n",
    "        #Display the frames    \n",
    "        cv2.imshow('Results Feed', bgr_frame)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "sample_video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
