{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e9ecc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import all the nessacary libraries to run the pose estimator\n",
    "\n",
    "#Import mediapipe to be used for the model\n",
    "import mediapipe as mp\n",
    "#Import opencv for rendaring and drawing capabilities\n",
    "import cv2\n",
    "\n",
    "import numpy as np #Handle numpy arrays\n",
    "import pandas as pd #Handle tabular data\n",
    "import os #Handle folder structure\n",
    "import pickle #Save and oad ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "70a2395c",
   "metadata": {},
   "outputs": [],
   "source": [
    "holistic_model = mp.solutions.holistic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4859f1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the model from the binary file\n",
    "with open('rfc_model.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6ca8f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate angle between 3 landmark points\n",
    "def calculate_pose_angle(start_point, mid_point, end_point):\n",
    "    #Convert landmark coords to numpy array\n",
    "    start_point = np.array(start_point) \n",
    "    mid_point = np.array(mid_point) \n",
    "    end_point = np.array(end_point) \n",
    "    \n",
    "    max_angle = 180.0\n",
    "    \n",
    "    #[0] = x, [1] = y, [2] = z\n",
    "    radians = np.arctan2(end_point[1] - mid_point[1], end_point[0] - mid_point[0]) - np.arctan2(start_point[1] - mid_point[1], start_point[0] - mid_point[0])\n",
    "    #Convert to an angle\n",
    "    angle = np.abs(radians * max_angle / np.pi)\n",
    "    \n",
    "    if angle > max_angle:\n",
    "        angle = 360 - angle\n",
    "        \n",
    "    return angle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "05d20c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exit!\n",
      "Class: Incorrect  Probability: 1.0\n"
     ]
    }
   ],
   "source": [
    "#PREDICT AND DISPLAY THE RESULTS OF THE MODEL BY PASSING THE TEST VIDEO\n",
    "\n",
    "#Connect the test video from the device\n",
    "sample_video = cv2.VideoCapture('datasets/invalid/5.invalid.mp4')\n",
    "\n",
    "\n",
    "# Curl counter variables\n",
    "reps = 0 \n",
    "command = None\n",
    "\n",
    "#Load the holistic model\n",
    "with holistic_model.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "    #Loop through each frame of the video \n",
    "    while sample_video.isOpened():\n",
    "        #Returns the status of the read and the frame as an image\n",
    "        status, frame = sample_video.read()\n",
    "        \n",
    "        #If frame is read correctly, status is true\n",
    "        if status == False:\n",
    "            print(\"Exit!\")\n",
    "            break\n",
    "          \n",
    "        #Recolor the captured frame from BGR to RGB (Medipipe requies frames to be in RGB format)\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        #Prevent writing and copying frame data to improve performance while making the detection\n",
    "        rgb_frame.flags.writeable = False        \n",
    "        \n",
    "        #Use holistic model to make detections\n",
    "        result_frame = holistic.process(rgb_frame)\n",
    "        #Set frame back to writable format after detection\n",
    "        rgb_frame.flags.writeable = True   \n",
    "        \n",
    "        #Recolor the captured frame from BGR for rendering with opencv\n",
    "        bgr_frame = cv2.cvtColor(rgb_frame, cv2.COLOR_RGB2BGR)        \n",
    "        #Predict the coordinates of the landmarks (results screen)\n",
    "        try:\n",
    "            #Extracting all the landmarks of the pose as an array\n",
    "            pose_landmarks_array = result_frame.pose_landmarks.landmark\n",
    "            #Format landmarks in to a numpy array for better structuring(removing keys) and collapse array to 1 dimesnsion\n",
    "            pose_landmarks_nparray = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] \n",
    "                                                    for landmark in pose_landmarks_array]).flatten() \n",
    "                                          if result_frame.pose_landmarks else np.zeros(33*4))\n",
    "\n",
    "            #Pass the numpy array into a data frame\n",
    "            features = pd.DataFrame([pose_landmarks_nparray])\n",
    "            #Store the top class of the prediction\n",
    "            pose_class_status = model.predict(features.values)[0]\n",
    "            #Store the probability of the prediction\n",
    "            pose_class_status_prob = model.predict_proba(features.values)[0]\n",
    "            #Retrieve x and y coords of the landmark points\n",
    "            left_shoulder = [pose_landmarks_array[holistic_model.PoseLandmark.LEFT_SHOULDER.value].x, \n",
    "                             pose_landmarks_array[holistic_model.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            left_elbow = [pose_landmarks_array[holistic_model.PoseLandmark.LEFT_ELBOW.value].x, \n",
    "                          pose_landmarks_array[holistic_model.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "            left_wrist = [pose_landmarks_array[holistic_model.PoseLandmark.LEFT_WRIST.value].x, \n",
    "                          pose_landmarks_array[holistic_model.PoseLandmark.LEFT_WRIST.value].y]\n",
    "            right_shoulder = [pose_landmarks_array[holistic_model.PoseLandmark.RIGHT_SHOULDER.value].x, \n",
    "                              pose_landmarks_array[holistic_model.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "            right_elbow = [pose_landmarks_array[holistic_model.PoseLandmark.RIGHT_ELBOW.value].x, \n",
    "                           pose_landmarks_array[holistic_model.PoseLandmark.RIGHT_ELBOW.value].y]\n",
    "            right_wrist = [pose_landmarks_array[holistic_model.PoseLandmark.RIGHT_WRIST.value].x, \n",
    "                           pose_landmarks_array[holistic_model.PoseLandmark.RIGHT_WRIST.value].y]\n",
    "            left_angle = calculate_pose_angle(left_shoulder, left_elbow, left_wrist)\n",
    "            right_angle = calculate_pose_angle(right_shoulder, right_elbow, right_wrist)\n",
    "            \n",
    "            # Curl counter logic\n",
    "            if left_angle > 140 and right_angle > 140:\n",
    "                command = \"Down\"\n",
    "            if left_angle < 90 and right_angle > 140 and command =='Down':\n",
    "                command = \"Up\"\n",
    "                if pose_class_status.split(' ')[0].lower == \"correct\":\n",
    "                    reps += 1\n",
    "                    print(reps)\n",
    "                    \n",
    "            #Set a rectangle box to display the results of the prediction in the video frame\n",
    "            #rectangle(container, top_coord, bottom_coord, color, line_thickness)\n",
    "            cv2.rectangle(bgr_frame, (0,0), (250, 150), (245, 117, 16), -1)\n",
    "            \n",
    "            cv2.putText(bgr_frame, 'Class'\n",
    "                        , (105,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "            \n",
    "            #Extract and display the top class of the prediction\n",
    "            cv2.putText(bgr_frame, pose_class_status.split(' ')[0]\n",
    "                        , (100,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            cv2.putText(bgr_frame, 'Probability'\n",
    "                        , (15,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "            \n",
    "            #Extract and display the maximum probability\n",
    "            cv2.putText(bgr_frame, str(round(pose_class_status_prob[np.argmax(pose_class_status_prob)],2))\n",
    "                        , (10,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            cv2.putText(bgr_frame, 'Reps'\n",
    "                        , (105,62), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "            \n",
    "            #Display the no of repatitions\n",
    "            cv2.putText(bgr_frame, str(reps)\n",
    "                        , (100,100), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            cv2.putText(bgr_frame, 'Stage'\n",
    "                        , (15,62), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "            \n",
    "            #Display the command\n",
    "            cv2.putText(bgr_frame, command\n",
    "                        , (10,100), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    " \n",
    "        except:\n",
    "            pass\n",
    "                        \n",
    "        #Display the frames  \n",
    "\n",
    "        cv2.imshow('Results Feed', bgr_frame)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    print(\"Class:\", pose_class_status, \" Probability:\", str(round(pose_class_status_prob[np.argmax(pose_class_status_prob)],2)))\n",
    "\n",
    "\n",
    "sample_video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23a1e05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
